## batch
[note_feature_split_key_container]
class_name = zensols.dataset.StratifiedStashSplitKeyContainer
stash = instance: note_feature_doc_stash
distribution = dict: {'train': 0.8, 'test': 0.1, 'validation': 0.1}
pattern = {name}.txt
key_path = path: ${sidmodel_default:corpus_dir}/dataset-row-ids
split_labels_path = path: ${sidmodel_default:temporary_dir}/feature-dataframe.dat
partition_attr = category
stratified_write = False

[note_split_feature_stash]
class_name = zensols.dataset.DatasetSplitStash
delegate = instance: note_feature_doc_stash
split_container = instance: note_feature_split_key_container

[batch_dir_stash]
groups = eval: (
    set('section_ids mask'.split()),
    set('note_category note_category_token'.split()),
    set('glove_50_embedding'.split()),
    set('glove_300_embedding'.split()),
    set('word2vec_300_embedding'.split()),
    set('fasttext_crawl_300_embedding'.split()),
    set('section_ids_trans masktrans transformer_fixed_embedding'.split()),
    set('majorsent_ids majorsent_id_mask'.split()),
    set('transformer_majorsent_fixed_embedding'.split()),
    set('transformer_majorsent_fixed_biobert_embedding'.split()),
    set('transformer_majorsent_trainable_embedding'.split()))

[batch_stash]
split_stash_container = instance: note_split_feature_stash
data_point_type = class: sidmodel.SectionDataPoint
batch_type = class: sidmodel.SectionBatch
batch_feature_mappings = None
decoded_attributes = set: section_ids, mask, ${deepnlp_default:embedding}
batch_size = 20
# rebatching using 2 workers for memory limitations
workers = 2
