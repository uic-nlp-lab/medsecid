# majority label across sentences
[majorsent_mapper]
class_name = sidmodel.MajorSentLabelMapper
section_ids_attribute = section_ids
majorsent_ids_attribute = majorsent_ids

[token_classify_majorsent_vectorizer]
class_name = sidmodel.MajorSentLabelVectorizer
feature_id = mslabel
encode_transformed = False
delegate_feature_id = tclabel1
fold_method = separate


# trainable embeddings (transformer_majorsent_trainable unused)
[transformer_majorsent_trainable_resource]
class_name = zensols.deepnlp.transformer.TransformerResource
torch_config = instance: gpu_torch_config
#model_id = bert-base-cased
#model_id = distilbert-base-cased
model_id = google/bigbird-roberta-base
cased = True
cache = False
trainable = True

[transformer_majorsent_trainable_tokenizer]
class_name = zensols.deepnlp.transformer.TransformerDocumentTokenizer
resource = instance: transformer_majorsent_trainable_resource
word_piece_token_length = 0

[transformer_majorsent_trainable_embedding]
class_name = zensols.deepnlp.transformer.TransformerEmbedding
tokenizer = instance: transformer_majorsent_trainable_tokenizer

[transformer_majorsent_trainable_feature_vectorizer]
class_name = sidmodel.MajorSentEmbeddingVectorizer
feature_id = mstrantrainable
fold_method = sentence
embed_model = instance: transformer_majorsent_trainable_embedding
encode_transformed = False

[transformer_majorsent_trainable_embedding_layer]
class_name = zensols.deepnlp.transformer.TransformerEmbeddingLayer
embed_model = instance: transformer_majorsent_trainable_embedding
feature_vectorizer = instance: language_feature_manager



# fixed embeddings
[transformer_majorsent_fixed_resource]
class_name = zensols.deepnlp.transformer.TransformerResource
torch_config = instance: gpu_torch_config
model_id = bert-base-cased
cased = True
cache = False
trainable = False

[transformer_majorsent_fixed_tokenizer]
class_name = zensols.deepnlp.transformer.TransformerDocumentTokenizer
resource = instance: transformer_majorsent_fixed_resource
word_piece_token_length = 0

[transformer_majorsent_fixed_embedding]
class_name = zensols.deepnlp.transformer.TransformerEmbedding
tokenizer = instance: transformer_majorsent_fixed_tokenizer

[transformer_majorsent_fixed_feature_vectorizer]
class_name = sidmodel.MajorSentTransformerEmbeddingFeatureVectorizer
feature_id = mstranfixed
fold_method = separate
embed_model = instance: transformer_majorsent_fixed_embedding
encode_transformed = True

[transformer_majorsent_fixed_embedding_layer]
class_name = zensols.deepnlp.transformer.TransformerEmbeddingLayer
embed_model = instance: transformer_majorsent_fixed_embedding
feature_vectorizer = instance: language_feature_manager

# used for majority label sentences with CRF
[majorsent_mask_vectorizer]
class_name = zensols.deeplearn.vectorize.MaskFeatureVectorizer
feature_id = msmask



# fixed biobert embeddings
[transformer_majorsent_fixed_biobert_resource]
class_name = zensols.deepnlp.transformer.TransformerResource
torch_config = instance: gpu_torch_config
model_id = dmis-lab/biobert-base-cased-v1.1
cased = True
cache = False
trainable = False

[transformer_majorsent_fixed_biobert_tokenizer]
class_name = zensols.deepnlp.transformer.TransformerDocumentTokenizer
resource = instance: transformer_majorsent_fixed_biobert_resource
word_piece_token_length = 0

[transformer_majorsent_fixed_biobert_embedding]
class_name = zensols.deepnlp.transformer.TransformerEmbedding
tokenizer = instance: transformer_majorsent_fixed_biobert_tokenizer

[transformer_majorsent_fixed_biobert_feature_vectorizer]
class_name = sidmodel.MajorSentTransformerEmbeddingFeatureVectorizer
feature_id = mstranfixed
fold_method = separate
embed_model = instance: transformer_majorsent_fixed_biobert_embedding
encode_transformed = True

[transformer_majorsent_fixed_biobert_embedding_layer]
class_name = zensols.deepnlp.transformer.TransformerEmbeddingLayer
embed_model = instance: transformer_majorsent_fixed_biobert_embedding
feature_vectorizer = instance: language_feature_manager
